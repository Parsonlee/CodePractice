{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "# 假设你希望使用 'SimHei'\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'WenQuanYi Zen Hei', 'Arial Unicode MS'] # 添加多个备用字体\n",
    "plt.rcParams['axes.unicode_minus'] = False # 解决负号 '-' 显示为方块的问题\n",
    "plt.rcParams['font.size'] = 12 # 可以适当调整字体大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relevance_scores(query_embeddings, document_embeddings):\n",
    "    \"\"\"\n",
    "    计算给定查询的前 k 个最相关文档。\n",
    "\n",
    "    参数:\n",
    "    query_embeddings: 表示查询嵌入的张量 (tensor),形状: [seq_len, d_model]\n",
    "    document_embeddings: 表示 k 个文档嵌入的张量,形状: [k, max_sql_len, d_model]\n",
    "\n",
    "    返回: 基于相关性分数排序的文档索引\n",
    "    \"\"\"\n",
    "\n",
    "    # 注: 假设 document_embeddings 已经进行了适当的填充并转移到 GPU\n",
    "\n",
    "    # 1. 计算查询嵌入和文档嵌入的批量点积\n",
    "    # scores = torch.matmul(query_embeddings.unsqueeze(0), document_embeddings.transpose(1, 2))\n",
    "    scores = torch.einsum(\"sd, kmd -> ksm\", query_embeddings, document_embeddings)\n",
    "    print(\"scores shape:\", scores.shape)  # 输出形状应为 [k, seq_len, max_sql_len]\n",
    "\n",
    "    # 2. 在文档词语维度上应用最大池化,找出每个查询词语的最大相似度\n",
    "    max_scores_per_query_term = scores.max(dim=2).values\n",
    "    print(\n",
    "        \"max_scores_per_query_term shape:\", max_scores_per_query_term.shape\n",
    "    )  # 输出形状应为 [k, seq_len]\n",
    "\n",
    "    # 3. 对查询词语的分数求和,得到每个文档的总分\n",
    "    total_scores = max_scores_per_query_term.sum(dim=1)\n",
    "    print(\"total_scores shape:\", total_scores.shape)  # 输出形状应为 [k]\n",
    "\n",
    "    # 4. 根据总分对文档进行降序排序\n",
    "    sorted_indices = total_scores.argsort(descending=True)\n",
    "\n",
    "    return sorted_indices\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置随机种子以保证结果可复现\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # 模拟输入数据\n",
    "    num_queries = 5  # 查询中的词数\n",
    "    embedding_dim = 768  # 假设使用BERT-base的嵌入维度\n",
    "    num_documents = 3  # 测试用文档数量\n",
    "    max_doc_length = 10  # 文档的最大长度\n",
    "\n",
    "    # 随机生成查询和文档嵌入\n",
    "    query_embeddings = torch.randn(num_queries, embedding_dim)\n",
    "    document_embeddings = torch.randn(num_documents, max_doc_length, embedding_dim)\n",
    "\n",
    "    # 计算相关性分数\n",
    "    relevance_scores = compute_relevance_scores(query_embeddings, document_embeddings)\n",
    "\n",
    "    print(\"相关性分数:\", relevance_scores)\n",
    "\n",
    "    # 根据相关性分数对文档进行排序\n",
    "    sorted_indices = relevance_scores.argsort(descending=True)\n",
    "    print(\"按相关性分数降序排列的文档索引:\", sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 创建一个示例的“高秩”矩阵 ---\n",
    "# 我们可以创建一个 M x N 的矩阵\n",
    "M, N = 100, 80\n",
    "# 为了演示，我们先创建一个真实的低秩矩阵，然后加上一些噪声，使其变成一个“高秩”但可近似的矩阵\n",
    "# 创建两个“瘦”矩阵，它们的乘积将是低秩的\n",
    "rank_k = 5 # 假设真实秩为 5\n",
    "U_true = np.random.rand(M, rank_k)\n",
    "V_true = np.random.rand(N, rank_k)\n",
    "\n",
    "# 真实的低秩矩阵\n",
    "original_low_rank_matrix = np.dot(U_true, V_true.T)\n",
    "\n",
    "# 加上一些随机噪声，使其变为一个“高秩”但有内在低秩结构的数据矩阵\n",
    "noise = np.random.randn(M, N) * 0.1 # 噪音强度\n",
    "A_original = original_low_rank_matrix + noise\n",
    "\n",
    "print(f\"原始矩阵 A_original 形状: {A_original.shape}\")\n",
    "print(f\"原始矩阵 A_original 的秩 (理论上，实际计算可能因噪声而接近满秩): {np.linalg.matrix_rank(A_original)}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 2. 使用奇异值分解 (SVD) 进行低秩分解 ---\n",
    "# SVD 将矩阵 A 分解为 U * S * Vh\n",
    "# U: 左奇异向量矩阵 (M x M)\n",
    "# s: 奇异值向量 (min(M, N) 长度)\n",
    "# Vh: 右奇异向量的共轭转置矩阵 (N x N)\n",
    "U, s, Vh = np.linalg.svd(A_original)\n",
    "\n",
    "print(f\"U 矩阵形状: {U.shape}\")\n",
    "print(f\"奇异值向量 s 的长度: {s.shape}\")\n",
    "print(f\"Vh 矩阵形状: {Vh.shape}\")\n",
    "print(\"\\n前10个奇异值 (SVD能够揭示矩阵的“能量”或重要性):\")\n",
    "print(s[:10])\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 3. 通过截断 SVD 实现低秩近似 ---\n",
    "# 我们选择一个比原始矩阵秩小得多的 k，来近似原矩阵\n",
    "approx_rank = 5 # 我们希望用秩为5的矩阵来近似\n",
    "\n",
    "if approx_rank > len(s):\n",
    "    approx_rank = len(s) # 确保不超过奇异值数量\n",
    "\n",
    "# 提取前 k 个奇异值、左奇异向量和右奇异向量\n",
    "U_k = U[:, :approx_rank]\n",
    "s_k = np.diag(s[:approx_rank]) # 将奇异值向量转换为对角矩阵\n",
    "Vh_k = Vh[:approx_rank, :]\n",
    "\n",
    "# 重构低秩近似矩阵 A_approx\n",
    "# A_approx = U_k * s_k * Vh_k\n",
    "A_approx = np.dot(U_k, np.dot(s_k, Vh_k))\n",
    "\n",
    "print(f\"低秩近似矩阵 A_approx 的形状: {A_approx.shape}\")\n",
    "print(f\"低秩近似矩阵 A_approx 的秩: {np.linalg.matrix_rank(A_approx)}\") # 理论上是 approx_rank\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 4. 比较原始矩阵和低秩近似矩阵 ---\n",
    "# 计算近似误差（Frobenius范数）\n",
    "approximation_error = np.linalg.norm(A_original - A_approx, 'fro')\n",
    "print(f\"原始矩阵和低秩近似矩阵之间的误差 (Frobenius范数): {approximation_error}\")\n",
    "\n",
    "# 可视化前几个奇异值，可以看到它们衰减得很快，这正是低秩矩阵的特征\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(s, 'o-')\n",
    "plt.title('Singular Values (奇异值)')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.axvline(x=approx_rank - 1, color='r', linestyle='--', label=f'Approximation Rank = {approx_rank}')\n",
    "plt.legend()\n",
    "plt.yscale('log') # 奇异值通常呈指数衰减，用对数坐标更清晰\n",
    "plt.show()\n",
    "\n",
    "# 进一步可视化，展示原始矩阵和近似矩阵的差异（如果矩阵足够小，可以显示图像）\n",
    "# 这里只显示一个小块，因为整个矩阵太大\n",
    "if M * N <= 2500: # 如果矩阵足够小，才尝试显示为图像\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(A_original, cmap='gray', aspect='auto')\n",
    "    plt.title('Original Matrix')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(A_approx, cmap='gray', aspect='auto')\n",
    "    plt.title(f'Low-Rank Approximation (rank={approx_rank})')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n矩阵太大，不适合直接可视化为图像，请检查数值。\")\n",
    "\n",
    "print(\"\\n--- 关键点总结 ---\")\n",
    "print(f\"原始矩阵存储参数量: {M * N}\")\n",
    "print(f\"低秩近似矩阵存储参数量 (U_k, s_k, Vh_k): {M * approx_rank + approx_rank + N * approx_rank} (不包括额外的对角矩阵存储，如果只存向量的话)\")\n",
    "print(f\"当 rank_k ({approx_rank}) 远小于 M({M}) 和 N({N}) 时，参数量大大减少，实现了压缩。\")\n",
    "print(\"例如，如果只存储 U_k 和 Vh_k，参数量为 (M+N)*approx_rank。\")\n",
    "print(f\"本例中：原始参数 {M*N} = {M*N}，近似参数 {(M+N)*approx_rank} = {(M+N)*approx_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM code practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "# 假设你希望使用 'SimHei'\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'WenQuanYi Zen Hei', 'Arial Unicode MS'] # 添加多个备用字体\n",
    "plt.rcParams['axes.unicode_minus'] = False # 解决负号 '-' 显示为方块的问题\n",
    "plt.rcParams['font.size'] = 12 # 可以适当调整字体大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size 1, seq length 6, dim 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "    [\n",
    "        [0.43, 0.15, 0.89],\n",
    "        [0.55, 0.87, 0.66],\n",
    "        [0.57, 0.85, 0.64],\n",
    "        [0.22, 0.58, 0.33],\n",
    "        [0.77, 0.25, 0.10],\n",
    "        [0.05, 0.80, 0.55],\n",
    "    ]\n",
    ")\n",
    "print(\"batch size 1, seq length 6, dim 3\")\n",
    "inputs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = inputs[1].shape[0]\n",
    "\n",
    "w_q = torch.nn.Parameter(torch.rand(d_model, d_model), requires_grad=False)\n",
    "w_k = torch.nn.Parameter(torch.rand(d_model, d_model), requires_grad=False)\n",
    "w_v = torch.nn.Parameter(torch.rand(d_model, d_model), requires_grad=False)\n",
    "\n",
    "x_2 = inputs[1]\n",
    "query_2 = x_2 @ w_q\n",
    "key_2 = x_2 @ w_k\n",
    "value_2 = x_2 @ w_v\n",
    "\n",
    "query_2\n",
    "\n",
    "attn_scores = inputs @ inputs.T\n",
    "attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "attn_weights @ inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_k(x)\n",
    "        values = self.W_v(x)\n",
    "        queries = self.W_q(x)\n",
    "\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[0]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2356, 0.5940, 0.2045],\n",
      "        [0.2364, 0.5991, 0.2040],\n",
      "        [0.2363, 0.5992, 0.2041],\n",
      "        [0.2371, 0.6000, 0.2047],\n",
      "        [0.2355, 0.6001, 0.2049],\n",
      "        [0.2376, 0.5995, 0.2044]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sa_v1 = SelfAttention_v2(3, 3)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqlen = 6\n",
    "torch.tril(torch.ones(seqlen, seqlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1385, 0.2379, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1390, 0.2369, 0.2326, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1435, 0.2074, 0.2046, 0.1462, 0.0000, 0.0000],\n",
       "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.0000],\n",
       "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_len = attn_weights.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_len, context_len))\n",
    "attn_weights * mask_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_sum = mask_simple.sum(dim=1, keepdim=True)\n",
    "mask_simple_norm = mask_simple / row_sum\n",
    "mask_simple_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.9544, 1.4950,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.9422, 1.4754, 1.4570,   -inf,   -inf,   -inf],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937,   -inf,   -inf],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654,   -inf],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_len, context_len), diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = torch.softmax(masked / d_model**0.5, dim=-1)\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = nn.Dropout(0.5)\n",
    "dropout(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementing compact causal self-attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0457, -0.1734, -0.2304],\n",
      "         [ 0.2276, -0.3493, -0.3021],\n",
      "         [ 0.2899, -0.4045, -0.3238],\n",
      "         [ 0.2786, -0.3888, -0.2985],\n",
      "         [ 0.2945, -0.3402, -0.2637],\n",
      "         [ 0.2819, -0.3639, -0.2719]],\n",
      "\n",
      "        [[ 0.0457, -0.1734, -0.2304],\n",
      "         [ 0.2276, -0.3493, -0.3021],\n",
      "         [ 0.2899, -0.4045, -0.3238],\n",
      "         [ 0.2786, -0.3888, -0.2985],\n",
      "         [ 0.2945, -0.3402, -0.2637],\n",
      "         [ 0.2819, -0.3639, -0.2719]]], grad_fn=<UnsafeViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_model, seq_len, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=qkv_bias)\n",
    "        self.W_k = nn.Linear(d_model, d_model, bias=qkv_bias)\n",
    "        self.W_v = nn.Linear(d_model, d_model, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_k(x)\n",
    "        queries = self.W_q(x)\n",
    "        values = self.W_v(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2)\n",
    "        mask = torch.triu(torch.ones(num_tokens, num_tokens), diagonal=1)\n",
    "        attn_scores = attn_scores.masked_fill_(\n",
    "            mask.bool()[:num_tokens, :num_tokens], -torch.inf\n",
    "        )\n",
    "        attn_weights = torch.softmax(attn_scores / d_in**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "    \n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(3, context_length, 0.0)\n",
    "\n",
    "context_vecs = ca(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2026,  0.0589],\n",
      "         [-0.2335,  0.1066],\n",
      "         [-0.2453,  0.1239],\n",
      "         [-0.2445,  0.1052],\n",
      "         [-0.2623,  0.1193],\n",
      "         [-0.2528,  0.1023]],\n",
      "\n",
      "        [[-0.2026,  0.0589],\n",
      "         [-0.2335,  0.1066],\n",
      "         [-0.2453,  0.1239],\n",
      "         [-0.2445,  0.1052],\n",
      "         [-0.2623,  0.1193],\n",
      "         [-0.2528,  0.1023]]], grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = (\n",
    "            d_out // num_heads\n",
    "        )  # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # combine heads, where self.d_out = num_heads * head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "    \n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
